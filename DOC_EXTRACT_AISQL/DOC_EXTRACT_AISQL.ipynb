{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "mzrb45o6xm56rapm4tvb",
   "authorId": "322325853055",
   "authorName": "CROMANO",
   "authorEmail": "chase.romano@snowflake.com",
   "sessionId": "ea8862d8-e99b-4c02-9873-66d74664c4c3",
   "lastEditTime": 1755143490015
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport time\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "create_stage"
   },
   "source": "create or replace stage EXAMPLE_DOCS \n\tDIRECTORY = ( ENABLE = true \n                  AUTO_REFRESH = TRUE) \n\tENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e1336684-5c11-4944-bba9-118d3a55df51",
   "metadata": {
    "name": "Load_docs_md",
    "collapsed": false
   },
   "source": "Load documents into a Snowflake stage"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "load_docs"
   },
   "source": "MY_STAGE = 'EXAMPLE_DOCS/machine_reports'\nMY_FILE_NAME = \"data/docs/machine_reports/*.pdf\"\n\n\n# Upload the file to a stage.\nput_result = session.file.put(MY_FILE_NAME, MY_STAGE, auto_compress=False,overwrite=True)\n\nMY_STAGE = 'EXAMPLE_DOCS/resumes'\nMY_FILE_NAME = \"data/docs/resumes/*.pdf\"\n\n\n# Upload the file to a stage.\nput_result = session.file.put(MY_FILE_NAME, MY_STAGE, auto_compress=False,overwrite=True)\nput_result[0].status",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ccf444cf-22b6-466e-91b5-a3a00ac7a680",
   "metadata": {
    "language": "sql",
    "name": "refresh_directory_table"
   },
   "outputs": [],
   "source": "alter stage example_docs refresh;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6bcde592-afa7-4fba-9140-8bb0cd5974aa",
   "metadata": {
    "name": "AI_EXTRACT_MD",
    "collapsed": false
   },
   "source": "AI_EXTRACT leverages Snowflake's Vision model Arctic-extract.  It is a vision model so we do not need to perform OCR, and then ask questions.  We can ask questions directly on documents.  Below we ask 2 questions about 1 document"
  },
  {
   "cell_type": "code",
   "id": "149218a4-9109-4940-b4e7-ecb91412406a",
   "metadata": {
    "language": "python",
    "name": "example_doc",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.image('data/docs/example_doc.png')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0c33b3c-0445-41d0-ac6f-560c1987d4d3",
   "metadata": {
    "language": "sql",
    "name": "Run_AI_Extract"
   },
   "outputs": [],
   "source": "SELECT AI_EXTRACT(\n  file => TO_FILE('@EXAMPLE_DOCS/machine_reports','Manual_2022-02-01.pdf'),\n  responseFormat => [['name', 'Who inspected the machine?'], ['date', 'What was the date of the inspection?']]\n) as json_data",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9800e75a-2a31-4a0a-9d43-ea7e0d887931",
   "metadata": {
    "name": "classification_md",
    "collapsed": false
   },
   "source": "We can even use it for classification"
  },
  {
   "cell_type": "code",
   "id": "39dd76df-fa8e-44b5-966c-d020e4859f8d",
   "metadata": {
    "language": "sql",
    "name": "use_for_classification"
   },
   "outputs": [],
   "source": "SELECT AI_EXTRACT(\n  file => TO_FILE('@EXAMPLE_DOCS/machine_reports','Manual_2022-02-01.pdf'),\n  responseFormat => [['name', 'does this doc have a name? Answer Yes or No']]\n) as json_data",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4eb1c339-39b8-4f4a-b379-ddc21cef2b07",
   "metadata": {
    "name": "Batch_Extract",
    "collapsed": false
   },
   "source": "Here we can run AI_EXTRACT on multiple files"
  },
  {
   "cell_type": "code",
   "id": "97a54541-b551-46a1-b849-ad63229054e8",
   "metadata": {
    "language": "sql",
    "name": "Parse_AI_Extract"
   },
   "outputs": [],
   "source": "SELECT \nrelative_path,\n  json_data:response.date::STRING as response_date,\n  json_data:response.name::STRING as inspector,\n  json_data:response.grade::STRING as grade,\n  json_data:response.machine::STRING as machine\nfrom\n(\nSELECT \nrelative_path,\nAI_EXTRACT(\n  file => TO_FILE('@EXAMPLE_DOCS',RELATIVE_PATH),\n  responseFormat => [['name', 'Who inspected the machine?'], \n  ['date', 'What was the date of the inspection?'],\n  ['grade', 'What was the grade of the inspection?'],\n  ['machine', 'What machine was inspected?']]\n) as json_data\nfrom DIRECTORY(@EXAMPLE_DOCS)\nwhere relative_path like 'machine_reports/%'\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3bb0c21b-3224-4d0e-abad-4a906c35703c",
   "metadata": {
    "name": "AI_Extract_Intro",
    "collapsed": false
   },
   "source": "Extract key information from resume using AI_EXTRACT"
  },
  {
   "cell_type": "code",
   "id": "5b544dca-bf08-4751-a794-47409e39184f",
   "metadata": {
    "language": "sql",
    "name": "AI_EXTRACT_RESUMES"
   },
   "outputs": [],
   "source": "SELECT \n  json_data:response.name::STRING as name,\n  json_data:response.email::STRING as email,\n  json_data:response.phone::STRING as phone_number\nfrom\n(\nSELECT AI_EXTRACT(\n  file => TO_FILE('@EXAMPLE_DOCS/resumes','resume-sample-2-13-1.pdf'),\n  responseFormat => [['name', 'What is the name of the resume applicant?'], \n  ['email', 'What is the email of the resume applicant?'],\n  ['phone', 'What is the phone number of the resume applicant?']]\n) as json_data);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e2bffbc-6c14-4da3-8b3e-4753e3276cca",
   "metadata": {
    "name": "Parse_intro",
    "collapsed": false
   },
   "source": "Parse text from a resume using PARSE_DOCUMENT"
  },
  {
   "cell_type": "code",
   "id": "18b8a706-6e35-44c3-8d1a-40d899038378",
   "metadata": {
    "language": "sql",
    "name": "Parse_resume"
   },
   "outputs": [],
   "source": "SELECT \nrelative_path,\nSNOWFLAKE.CORTEX.PARSE_DOCUMENT('@EXAMPLE_DOCS',relative_path):content::STRING AS resume_text,\nfrom DIRECTORY(@EXAMPLE_DOCS)\nwhere relative_path like 'resumes/%'\nlimit 5;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4c3b1dd-318c-4385-b678-b58d1d3f5e52",
   "metadata": {
    "name": "Candidate_Intro",
    "collapsed": false
   },
   "source": "Combine PARSE_DOCUMENT and AI_EXTRACT to create candidates table"
  },
  {
   "cell_type": "code",
   "id": "d1a9b5f1-93b8-40bf-9ded-9e4511242cf3",
   "metadata": {
    "language": "sql",
    "name": "Create_Candidate_Table"
   },
   "outputs": [],
   "source": "create or replace table candidates as \nSELECT \n  json_data:response.name::STRING as name,\n  json_data:response.email::STRING as email,\n  json_data:response.phone::STRING as phone_number,\n  resume_text,\n  relative_path as resume_file_path,\nfrom\n(\nSELECT \n    relative_path,\n    \n    AI_EXTRACT(\n        file => TO_FILE('@EXAMPLE_DOCS',relative_path),\n        responseFormat => [['name', 'What is the name of the resume applicant?'], \n          ['email', 'What is the email of the resume applicant?'],\n          ['phone', 'What is the phone number of the resume applicant?']]\n    ) as json_data,\n    \n    SNOWFLAKE.CORTEX.PARSE_DOCUMENT('@EXAMPLE_DOCS',relative_path):content::STRING AS resume_text\n\nfrom DIRECTORY(@EXAMPLE_DOCS)\nwhere relative_path like 'resumes/%');\n\nselect * from candidates;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd2fd6ea-a0f7-44d6-aa90-54bd955de5be",
   "metadata": {
    "name": "Jobs_Intro",
    "collapsed": false
   },
   "source": "Create Jobs table"
  },
  {
   "cell_type": "code",
   "id": "4848ac51-d701-4f9f-8ac1-58be19361ce1",
   "metadata": {
    "language": "sql",
    "name": "Create_Jobs_Table"
   },
   "outputs": [],
   "source": "-- Create table\nCREATE OR REPLACE TABLE JOBS (\n  job_id INTEGER AUTOINCREMENT,\n  job_title VARCHAR,\n  job_category VARCHAR,\n  job_description VARCHAR,\n  created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (job_id)\n);\n\n-- Seed data (10 rows)\nINSERT INTO JOBS (job_title, job_category, job_description) VALUES\n  ('Network Engineer', 'computer networking',\n   'Design, implement, and troubleshoot enterprise LAN/WAN and wireless networks. Configure routers, switches, and firewalls with high availability. Monitor performance using SNMP/NetFlow and packet analysis. Collaborate on capacity planning and network upgrades.'),\n  ('Network Security Analyst', 'computer networking',\n   'Monitor and analyze network traffic for threats and anomalies. Manage firewalls, IDS/IPS, and VPNs following zero-trust principles. Investigate incidents and produce actionable remediation plans. Maintain security baselines and compliance documentation.'),\n  ('Backend Software Engineer', 'software development',\n   'Build scalable APIs and services with robust domain models and clean interfaces. Optimize data access patterns and background processing. Write comprehensive tests and instrumentation for reliability. Participate in code reviews and architecture discussions.'),\n  ('Software Engineer', 'software development',\n   'Develop responsive, accessible web interfaces with modern frameworks. Integrate APIs and manage application state efficiently. Optimize performance, bundle size, and rendering. Maintain a high-quality component library and UI tests.'),\n  ('DevOps Engineer', 'software development',\n   'Automate CI/CD pipelines and infrastructure as code. Improve observability with logs, metrics, and tracing. Harden deployments with blue/green and canary strategies. Optimize cost and reliability across environments.'),\n  ('Data Engineer', 'software development',\n   'Design and maintain reliable ETL/ELT pipelines and data models. Orchestrate workflows and ensure data quality and lineage. Tune warehouses and storage for performance. Partner with analytics and ML teams on scalable datasets.'),\n  ('Marketing Manager', 'marketing',\n   'Own go-to-market plans and integrated campaigns across channels. Define positioning, messaging, and audience segmentation. Track funnel metrics and ROI to optimize spend. Coordinate launches with sales and product teams.'),\n  ('Digital Marketing Specialist', 'marketing',\n   'Execute SEO, SEM, and paid social campaigns end-to-end. Create and test creatives and landing pages for conversion. Analyze performance and run A/B tests to improve CAC. Maintain accurate tracking and attribution.'),\n  ('Corporate Trainer', 'personnel training',\n   'Deliver engaging instructor-led and virtual training programs. Assess skill gaps and tailor curricula to business goals. Measure learning outcomes and iterate content. Coach subject matter experts to scale delivery.'),\n  ('Instructional Designer', 'personnel training',\n   'Design learner-centered courses using modern instructional frameworks. Develop eLearning modules, labs, and assessments. Align objectives with measurable outcomes. Maintain content libraries and update materials regularly.');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03fff09e-cb6a-407b-9ac1-385ad79dc3d1",
   "metadata": {
    "language": "sql",
    "name": "Join_Candidate_w_Job"
   },
   "outputs": [],
   "source": "SELECT job_title, job_description, resume_text, name, email, phone_number\nFROM candidates c\nJOIN JOBS j\nON AI_FILTER(PROMPT('Does the following resume {0} fit this job description {1}?', c.resume_text, j.job_description));",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6798c01-c188-4cda-ab06-94df686c5eab",
   "metadata": {
    "name": "AI_Classify_Intro",
    "collapsed": false
   },
   "source": "Classify candidates as entry level, management level, or executive"
  },
  {
   "cell_type": "code",
   "id": "ff792581-d32a-4693-b55a-059eb7e2a042",
   "metadata": {
    "language": "sql",
    "name": "Classify_Candidates"
   },
   "outputs": [],
   "source": "Select *,\n    AI_CLASSIFY(\n        resume_text, \n        ['entry level', 'management level', 'executive level'],\n        {\n            'task_description':'Categorize the candidate into one of the given levels of expertise'\n        }):labels[0]::string as expertise\nfrom candidates;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "920d99b4-9bf0-4286-8bc5-b2b20751b6e6",
   "metadata": {
    "name": "AI_AGG_Intro",
    "collapsed": false
   },
   "source": "Use AI_AGG to look across all of the machine reports"
  },
  {
   "cell_type": "code",
   "id": "e97b6f4d-8bd2-4a46-a772-218402441f02",
   "metadata": {
    "language": "sql",
    "name": "AI_AGG"
   },
   "outputs": [],
   "source": "with parsed_reports as (\nSELECT \nSNOWFLAKE.CORTEX.PARSE_DOCUMENT('@EXAMPLE_DOCS',relative_path):content::STRING AS report_text\nfrom DIRECTORY(@EXAMPLE_DOCS)\nwhere relative_path like 'machine_reports/%'\n)\nSelect \n    AI_AGG(report_text, 'What were the main reasons for machines not passing inspection?')\nfrom parsed_reports;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7856588a-f71a-4502-911c-502979199606",
   "metadata": {
    "name": "summarize",
    "collapsed": false
   },
   "source": "Use AI_AGG to extract skills accross expertise"
  },
  {
   "cell_type": "code",
   "id": "020ff151-462b-48bb-95e4-b44f6fb2d7f7",
   "metadata": {
    "language": "sql",
    "name": "experties_table"
   },
   "outputs": [],
   "source": "create or replace temporary table expertise as\nSelect resume_text,\n    AI_CLASSIFY(\n        resume_text, \n        ['entry level', 'management level', 'executive level'],\n        {\n            'task_description':'Categorize the candidate into one of the given levels of expertise'\n        }):labels[0]::string as expertise\nfrom candidates;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64b031db-10b3-4bc0-8130-7908e5ec3989",
   "metadata": {
    "language": "sql",
    "name": "AI_AGG_GROUP_BY"
   },
   "outputs": [],
   "source": "SELECT expertise,\n       AI_AGG(resume_text, 'What are some common skills across these resumes?  List them in an array []') AS summarized_resumes\n  FROM expertise\n GROUP BY expertise;",
   "execution_count": null
  }
 ]
}