{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "4zh66zqhwmdtmyxx74yf",
   "authorId": "4927852566776",
   "authorName": "CHASE",
   "authorEmail": "chase.romano@snowflake.com",
   "sessionId": "2729ca89-144c-4cfa-8046-b497afed88ba",
   "lastEditTime": 1758898717561
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom snowflake.ml.registry import Registry\n\n#add another package\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "56066407-bba0-4d10-98f5-2f6dae0145d3",
   "metadata": {
    "language": "python",
    "name": "get_data",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "titanic = pd.read_csv('data/titanic_snowflake.csv')\ntitanic = titanic.drop([\"AGE\", \n                        \"DECK\", \n                        \"ALIVE\",\n                        \"ADULT_MALE\",\n                        \"EMBARKED\",\n                        \"PCLASS\",\n                        \"ALONE\",\n                        \"SEX\"],axis=1)\ntitanic.head()\n     ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a53f4ef-a085-439c-ab79-68c4a0deec18",
   "metadata": {
    "name": "Get_Data_From_Snowflake",
    "collapsed": false
   },
   "source": "Usually your data will already be in Snowflake.  This next step shows how to write the pandas dataframe as a table, then how to turn a table from Snowflake into a pandas dataframe"
  },
  {
   "cell_type": "code",
   "id": "4e117fbf-2fc7-444c-a99a-21b6a1aaffac",
   "metadata": {
    "language": "python",
    "name": "write_to_table"
   },
   "outputs": [],
   "source": "# This step turns pandas -> snowpark and writes to snowflake\ntitanic_sf = session.create_dataframe(titanic)\ntitanic_sf.write.mode(\"overwrite\").save_as_table(\"titanic_raw\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b684830-9d7b-4cce-842d-ebcb061935a3",
   "metadata": {
    "language": "python",
    "name": "Read_table_pandas"
   },
   "outputs": [],
   "source": "# Here we read a table from Snowflake into a Snowpark dataframe\n\ntitanic_raw = session.table('titanic_raw').to_pandas()\ntitanic_raw.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb1acb42-85cd-4fc2-a1e6-edcc5704ec45",
   "metadata": {
    "language": "python",
    "name": "Build_Pipeline",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Define X and y\nX = titanic.drop('SURVIVED', axis=1)\ny = titanic['SURVIVED']\n\n# Identify column types\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\nboolean_cols = X.select_dtypes(include=['bool']).columns.tolist()\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.difference(boolean_cols).tolist()\n\n# Boolean to int transformer\nbool_to_int = FunctionTransformer(lambda df: df.astype(int), validate=False)\n\n# Preprocessing for numeric, categorical, and boolean\nnumeric_transformer = SimpleImputer(strategy='mean')\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n])\n\nboolean_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('to_int', bool_to_int)\n])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numeric_transformer, numeric_cols),\n    ('cat', categorical_transformer, categorical_cols),\n    ('bool', boolean_transformer, boolean_cols)\n])\n\n# Final pipeline\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', XGBClassifier(objective='binary:logistic', eval_metric='logloss'))\n])\n\n# Parameter grid for GridSearchCV\nparam_grid = {\n    'classifier__n_estimators': [100, 200],\n    'classifier__learning_rate': [0.1, 0.5],\n    'classifier__max_depth': [1, 2, 3, 4, 5, 6],\n    'classifier__min_child_weight': [1, 6]\n}\n\n# Split data\nxtrain, xtest, ytrain, ytest = train_test_split(X, y, train_size=0.7, random_state=1234)\n\n# Grid search\ngrid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\ngrid_search.fit(xtrain, ytrain)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9597a1b5-fa80-482b-9279-96dc72020697",
   "metadata": {
    "language": "python",
    "name": "get_best_params",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Best parameters and score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)\n\n# Evaluate the best model on the test set\nbest_model = grid_search.best_estimator_\ntest_score = best_model.score(xtest, ytest)\nprint(\"Test Score:\", test_score)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0e53e21-e9d6-453d-8149-448270476258",
   "metadata": {
    "language": "python",
    "name": "show_metrics",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "metrics = {\n    \"Accuracy\": best_score,\n    \"Params\": best_params\n}\n\nmetrics",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b263614f-9d84-463f-a37d-f4b787889ec4",
   "metadata": {
    "language": "python",
    "name": "register_model",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Get sample input data to pass into the registry logging function\nX = xtrain.sample(n=1)\n\n# Create a registry and log the model\n# You can specify a different DB and Schema if you'd like\n# otherwise it uses the session context\n# If a registry does not exist it will create one\nreg = Registry(session=session)\n\n# Define model name and version (use uppercase for name)\nmodel_name = \"TITANIC_SERVICE_PIPE\"\n\ntitanic_model = reg.log_model(\n    model_name=model_name,\n    target_platforms=[\"SNOWPARK_CONTAINER_SERVICES\"],# Deploying online so SPCS\n    #version_name=\"V_1\", # If you leave version_name off SF creates one\n    model=best_model,\n    sample_input_data=X,\n    metrics=metrics,\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18c5b6b9-9b81-4671-b3a2-4d23d437023e",
   "metadata": {
    "language": "python",
    "name": "show_models",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "models_df = reg.show_models()\nmodels_df[models_df['name'] == model_name]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5538ef69-e58c-4c1d-8af0-3c99c0e9f14e",
   "metadata": {
    "language": "python",
    "name": "show_model_versions",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "models = reg.get_model(model_name).show_versions()\nmodels.sort_values(by='created_on', ascending=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "974ebd8f-407a-4aa1-9cf7-5ac161e8fbd1",
   "metadata": {
    "language": "python",
    "name": "Show_Recent_Model"
   },
   "outputs": [],
   "source": "recent_model = reg.get_model(model_name).last()\nrecent_model",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "774fde38-6f47-4919-8eca-19619f1a8818",
   "metadata": {
    "language": "python",
    "name": "promote_model",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "m = reg.get_model(model_name).last()\nm.default = m\nmv = m.default\nmv.version_name",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e696db7-7ec9-48f5-8cca-6e6dcd6101a5",
   "metadata": {
    "language": "sql",
    "name": "Create_Image_repo"
   },
   "outputs": [],
   "source": "-- If you do not have an image repo create on\nCREATE IMAGE REPOSITORY IF NOT EXISTS tutorial_repository;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c97be8bc-0ccc-4dbd-badf-caf48844e3eb",
   "metadata": {
    "name": "_Deploy_as_Service",
    "collapsed": false
   },
   "source": "### Deploying a Model to Snowpark Container Services as a Long-Running Service\n\nThis section explains how to deploy a machine learning model to Snowpark Container Services (SPCS) using Model Serving. The deployed service will run continuously and expose a REST API endpoint for prediction.\n\nIf you're currently using `system_compute_pool_CPU`, you will need to create a separate compute pool to host the service. \n\n> ### You may need `SYSADMIN` privileges to create a compute pool.\n\n```sql\nCREATE COMPUTE POOL compute_pool_name\n  MIN_NODES = 1\n  MAX_NODES = 1\n  INSTANCE_FAMILY = CPU_X64_XS;\n'''"
  },
  {
   "cell_type": "code",
   "id": "51653ef1-ef8d-4db8-9431-0c722c01786d",
   "metadata": {
    "language": "sql",
    "name": "Create_Compute_Pool"
   },
   "outputs": [],
   "source": "-- If you do not have a compute pool create one\nCREATE COMPUTE POOL IF NOT EXISTS titanic_compute_pool\n  MIN_NODES = 1\n  MAX_NODES = 2\n  INSTANCE_FAMILY = CPU_X64_M;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a6b4713-18c2-46c8-8862-b93fdd375c5c",
   "metadata": {
    "language": "python",
    "name": "Define_Variables_for_deployment"
   },
   "outputs": [],
   "source": "image_repo_name = \"tutorial_repository\"\n\ncp_name = \"titanic_compute_pool\"\nnum_spcs_nodes = '1'\nservice_name = 'TITANIC_PIPE_PREDICTION_SERVICE'\n\ncurrent_database = session.get_current_database().replace('\"', '')\ncurrent_schema = session.get_current_schema().replace('\"', '')\nextended_image_repo_name = f\"{current_database}.{current_schema}.{image_repo_name}\"\nextended_service_name = f'{current_database}.{current_schema}.{service_name}'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "573d5fc2-d359-4ca4-a7b9-0f32e4ea35d8",
   "metadata": {
    "language": "sql",
    "name": "drop_existing_service"
   },
   "outputs": [],
   "source": "DROP SERVICE IF EXISTS {{service_name}};",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "108cd9b1-be5d-46f5-bcfb-2419cefbd662",
   "metadata": {
    "language": "python",
    "name": "Create_service"
   },
   "outputs": [],
   "source": "# This step may take a few minutes\nmv.create_service(\n    service_name=extended_service_name,\n    service_compute_pool=cp_name,\n    image_repo=extended_image_repo_name,\n    ingress_enabled=True,\n    max_instances=int(num_spcs_nodes),\n    build_external_access_integration=\"ALLOW_ALL_INTEGRATION\"\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1d3697f-45a5-43a2-9e14-c381b2e86d4d",
   "metadata": {
    "language": "sql",
    "name": "Show_Compute_pool"
   },
   "outputs": [],
   "source": "-- Show the compute pool has a service\ndescribe compute pool titanic_compute_pool;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6aea5085-43db-4058-8fe7-7238cb9da982",
   "metadata": {
    "language": "sql",
    "name": "Show_Service"
   },
   "outputs": [],
   "source": "SHOW SERVICES LIKE '%TITANIC_PIPE_PREDICTION_SERVICE%';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a42d056-af4f-4424-bc7f-0afe72db7316",
   "metadata": {
    "language": "python",
    "name": "Show_Model_service"
   },
   "outputs": [],
   "source": "# Can also view this in the Model Registry UI\n# Give this a minute for the inference endpoint to populate\nmv.list_services()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e64cd091-e0bb-4a7b-b042-0726db194ec7",
   "metadata": {
    "language": "python",
    "name": "Create_Test_df"
   },
   "outputs": [],
   "source": "test_sf = session.create_dataframe(X.reset_index()).drop('\"index\"')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38f0c0e1-a6de-469a-ab26-e2fe3db44d56",
   "metadata": {
    "language": "python",
    "name": "Run_Predictions"
   },
   "outputs": [],
   "source": "mv.run(test_sf, \n            function_name = \"PREDICT\", \n            service_name = \"TITANIC_PIPE_PREDICTION_SERVICE\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "293f42e3-29b4-41a9-88f9-dc7b8c39272e",
   "metadata": {
    "name": "Streamlit_app",
    "collapsed": false
   },
   "source": "## Take streamlit_app.py, copy and paste in a SiS app and watch the model run in miliseconds"
  },
  {
   "cell_type": "markdown",
   "id": "e11e4638-2f8b-43b2-9c36-779a615290a9",
   "metadata": {
    "name": "drop_service_md",
    "collapsed": false
   },
   "source": "Since we created a REST API above, this service will run continuously. It is a good idea to drop or suspend the service if you do not need it. Compute pool will automatically suspend if no service is running."
  },
  {
   "cell_type": "markdown",
   "id": "1886e7cc-0046-4a90-a619-e9df7bf068e4",
   "metadata": {
    "name": "STOP_SERVICE",
    "collapsed": false
   },
   "source": "## Make sure to stop the service at the end of the demo so it does not stay on"
  },
  {
   "cell_type": "code",
   "id": "af852e91-1371-445b-9047-1ea071c9277c",
   "metadata": {
    "language": "sql",
    "name": "Drop_service"
   },
   "outputs": [],
   "source": "-- ALTER SERVICE {{service_name}} SUSPEND;",
   "execution_count": null
  }
 ]
}