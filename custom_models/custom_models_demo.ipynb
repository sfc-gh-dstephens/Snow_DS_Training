{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "# ===========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# We will use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "# Get the active Snowpark session (will raise if none is available).\n",
    "# When imported into Snowsight an active session will be present.\n",
    "session = get_active_session()\n",
    "\n",
    "# Configuration: for Snowsight imports we use the active session's current\n",
    "# database and schema so there are no hard-coded names. Registry actions\n",
    "# will run by default when the notebook is executed in Snowsight.\n",
    "USE_REGISTRY = True\n",
    "# Obtain the current database and schema from the active Snowpark session\n",
    "# This ensures the notebook adapts to whichever account/schema the user has selected in Snowsight.\n",
    "current = session.sql(\"select current_database() as db, current_schema() as schema\").collect()\n",
    "if len(current) > 0:\n",
    "    DB_NAME = current[0][0]\n",
    "    SCHEMA_NAME = current[0][1]\n",
    "else:\n",
    "    # Fallback to generic names if the query fails for any reason\n",
    "    DB_NAME = 'MODELS'\n",
    "    SCHEMA_NAME = 'XGB_MODELS'\n",
    "\n",
    "print(f'USE_REGISTRY={USE_REGISTRY}, DB={DB_NAME}, SCHEMA={SCHEMA_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77568396-3ce4-4123-aec7-065f622fe460",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Step 1 - Generate a Dataset with a Dominant Hidden Signal\n",
    "# ===================================================================\n",
    "print(\"Generating a synthetic dataset where base_margin is critical...\")\n",
    "\n",
    "# Define a single input feature that our models will be allowed to see.\n",
    "X_feature = np.linspace(start=-10, stop=10, num=10000)\n",
    "\n",
    "# 1. Create a simple, learnable signal based on the input feature.\n",
    "#    This is the part of the problem that a standard model CAN learn.\n",
    "y_known_signal = X_feature**2 * 2  # A simple parabola\n",
    "\n",
    "# 2. Create a dominant \"hidden\" signal that is INDEPENDENT of the input X_feature.\n",
    "#    A model cannot learn this pattern from X_feature alone; it's the \"secret key\".\n",
    "hidden_indices = np.linspace(0, 100, 10000) # An independent axis for the hidden signal\n",
    "y_hidden_signal = np.sin(hidden_indices) * 1000 # A sine wave\n",
    "\n",
    "# 3. Combine the signals and add random noise to create the final target value, y.\n",
    "#    The value of y is mostly determined by the hidden signal.\n",
    "noise = np.random.normal(0, 20, 10000)\n",
    "y = y_known_signal + y_hidden_signal + noise\n",
    "\n",
    "# 4. Create the final feature DataFrame 'X' for the model.\n",
    "#    CRUCIALLY, it ONLY contains the 'X_feature' and has no information about the hidden signal.\n",
    "X = pd.DataFrame({'X_feature': X_feature})\n",
    "\n",
    "# 5. Split all data arrays together.\n",
    "#    This is critical to ensure that X_train, y_train, and hidden_train all correspond\n",
    "#    to the same rows, which allows us to use `hidden_train` as the base_margin later.\n",
    "X_train, X_test, y_train, y_test, hidden_train, hidden_test = train_test_split(\n",
    "    X, y, y_hidden_signal, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nNew synthetic data generated and split successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218eecb-c189-46a1-bd3b-487bd33bf1ab",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Step 2 & 3 - Train and Evaluate Both Models\n",
    "# =====================================================\n",
    "\n",
    "# --- Model 1: Standard XGBoost ---\n",
    "print(\"\\n--- Training Model 1: Standard XGBoost Regressor ---\")\n",
    "model_1 = xgb.XGBRegressor(random_state=42)\n",
    "model_1.fit(X_train, y_train)\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "mse_1 = mean_squared_error(y_test, y_pred_1)\n",
    "\n",
    "print(\"\\n--- Performance of Model 1 (Standard XGBoost) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_1:.4f}  <-- Very high, as it cannot predict the dominant hidden signal.\")\n",
    "\n",
    "# --- Model 2: XGBoost with base_margin ---\n",
    "print(\"\\n--- Training Model 2: XGBoost Regressor with base_margin ---\")\n",
    "\n",
    "# The base_margin IS the hidden signal. This gives the model the \"secret key\".\n",
    "model_2 = xgb.XGBRegressor(random_state=42)\n",
    "model_2.fit(X_train, y_train, base_margin=hidden_train)\n",
    "y_pred_2 = model_2.predict(X_test, base_margin=hidden_test)\n",
    "mse_2 = mean_squared_error(y_test, y_pred_2)\n",
    "\n",
    "print(\"\\n--- Performance of Model 2 (XGBoost with base_margin) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_2:.4f}  <-- Much better, as it only needs to learn the simple remaining signal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0342c7-28b2-4716-bdce-b3c9dffeaf7c",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Step 4 - Visualize and Compare the Dramatic Difference\n",
    "# ================================================================\n",
    "print(\"\\nGenerating visualization...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "fig.suptitle(\"Test Set Performance: Demonstrating the Power of base_margin\", fontsize=18)\n",
    "\n",
    "# Sort values for clean line plotting\n",
    "sorted_indices = X_test['X_feature'].argsort()\n",
    "X_test_sorted = X_test.iloc[sorted_indices]\n",
    "y_test_sorted = y_test[sorted_indices]\n",
    "y_pred_1_sorted = y_pred_1[sorted_indices]\n",
    "y_pred_2_sorted = y_pred_2[sorted_indices]\n",
    "\n",
    "# Plot for Model 1 (Standard)\n",
    "# Its prediction is a simple parabola, missing the huge variance from the hidden signal.\n",
    "ax1.scatter(X_test_sorted['X_feature'], y_test_sorted, s=5, alpha=0.2, label='Actual Values')\n",
    "ax1.plot(X_test_sorted['X_feature'], y_pred_1_sorted, color='red', linewidth=1, label='Predicted Values')\n",
    "ax1.set_title(f\"Model 1: Standard XGBoost \\nMSE = {mse_1:.4f}\")\n",
    "ax1.set_xlabel(\"Feature\")\n",
    "ax1.set_ylabel(\"Target\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot for Model 2 (with base_margin)\n",
    "# Its prediction perfectly traces the actual data because it was given the hidden signal.\n",
    "ax2.scatter(X_test_sorted['X_feature'], y_test_sorted, s=5, alpha=0.2, label='Actual Values')\n",
    "ax2.plot(X_test_sorted['X_feature'], y_pred_2_sorted, color='green', linewidth=1, label='Predicted Values')\n",
    "ax2.set_title(f\"Model 2: XGBoost with base_margin does better\\nMSE = {mse_2:.4f}\")\n",
    "ax2.set_xlabel(\"Feature\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fc90e-592f-4eff-8ae0-de831463d9bc",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Step 4 - Define and Log the Custom Model\n",
    "# ==============================================================\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# --- 3a. Define the ModelContext with the in-memory model ---\n",
    "# We pass the trained model directly as a keyword argument.\n",
    "model_context = custom_model.ModelContext(\n",
    "    xgb_model_for_inference = model_2\n",
    ")\n",
    "\n",
    "# --- 4b. Define the Custom Model Class ---\n",
    "# This class acts as a wrapper that knows how to handle the base_margin input.\n",
    "class PassThroughMarginModel(custom_model.CustomModel):\n",
    "    def __init__(self, context: custom_model.ModelContext) -> None:\n",
    "        super().__init__(context)\n",
    "        self.model = self.context[\"xgb_model_for_inference\"]\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Separate the base_margin column from the actual features\n",
    "        base_margin = X['BASE_MARGIN']\n",
    "        model_features = X.drop(columns=['BASE_MARGIN'])\n",
    "        \n",
    "        # Pass both to the underlying model's predict function\n",
    "        predictions = self.model.predict(model_features, base_margin=base_margin)\n",
    "        \n",
    "        return pd.DataFrame({'PREDICTION': predictions})\n",
    "\n",
    "# --- 4c. Prepare for Logging ---\n",
    "# Create a sample input DataFrame that includes the BASE_MARGIN column\n",
    "X_train_with_margin = X_train.copy()\n",
    "X_train_with_margin['BASE_MARGIN'] = hidden_train\n",
    "\n",
    "# Initialize registry handle using the active session's DB/schema\n",
    "# This ensures `registry` is defined before we check it below (safe for top-to-bottom runs).\n",
    "registry = None\n",
    "if USE_REGISTRY:\n",
    "    registry = Registry(session=session, database_name=DB_NAME, schema_name=SCHEMA_NAME)\n",
    "\n",
    "# --- 4d. Log the Model (conditional) ---\n",
    "if USE_REGISTRY and registry is not None:\n",
    "    print(\"\\nLogging the custom model that accepts base_margin...\")\n",
    "    custom_model_to_log = PassThroughMarginModel(context=model_context)\n",
    "\n",
    "    model_version = registry.log_model(\n",
    "        model=custom_model_to_log,\n",
    "        model_name=\"XGB_WITH_PASSTHROUGH_MARGIN\",\n",
    "        version_name=\"v1\",\n",
    "        comment=\"Custom XGBoost model that accepts a base_margin column during inference.\",\n",
    "        conda_dependencies=[\"scikit-learn\", \"xgboost\", \"pandas\"],\n",
    "        sample_input_data=X_train_with_margin.head(100),\n",
    "        options={'relax_version': False}\n",
    "    )\n",
    "    print(\"Custom model logged successfully!\")\n",
    "else:\n",
    "    print(\"USE_REGISTRY is False or registry unavailable - skipping model logging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e52284-bcc5-484c-8997-7e3c919418e3",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Make Predictions with the Logged Model in Python\n",
    "# ==========================================================\n",
    "import pandas as pd\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Assume 'session' is your active Snowpark session.\n",
    "# session = Session.builder.getOrCreate() # Or get_active_session() in a notebook\n",
    "\n",
    "# Define your registry's database and schema (only used if USE_REGISTRY=True)\n",
    "if USE_REGISTRY:\n",
    "    registry = Registry(session=session, database_name=DB_NAME, schema_name=SCHEMA_NAME)\n",
    "\n",
    "# --- Step 1: Reference the specific model version ---\n",
    "if USE_REGISTRY:\n",
    "    # We can either use the `model_version` object directly from the previous cell\n",
    "    # or look it up like this:\n",
    "    model_name = \"XGB_WITH_PASSTHROUGH_MARGIN\"\n",
    "    version_name = \"v1\" # Use the version we might have logged\n",
    "    try:\n",
    "        retrieved_model_version = registry.get_model(model_name).version(version_name)\n",
    "        print(f\"Retrieved model: {retrieved_model_version.model_name}, Version: {retrieved_model_version.version_name}\")\n",
    "    except Exception as e:\n",
    "        retrieved_model_version = None\n",
    "        print(f\"Could not retrieve model from registry: {e}.\")\n",
    "else:\n",
    "    retrieved_model_version = None\n",
    "    print(\"USE_REGISTRY is False - skipping registry retrieval and inference via registry.\")\n",
    "\n",
    "# --- Step 2: Prepare the input data ---\n",
    "# Our input DataFrame MUST have columns with the exact names the model was trained on,\n",
    "# including the special 'BASE_MARGIN' column. We already have X_test/hidden_test in memory.\n",
    "X_test_with_margin = X_test.copy()\n",
    "X_test_with_margin['BASE_MARGIN'] = hidden_test\n",
    "X_test_with_margin = X_test_with_margin.reset_index(drop=True)\n",
    "\n",
    "# Convert the Pandas DataFrame to a Snowpark DataFrame if we will call the registry\n",
    "inference_data_snowpark = None\n",
    "if USE_REGISTRY and retrieved_model_version is not None:\n",
    "    inference_data_snowpark = session.create_dataframe(X_test_with_margin)\n",
    "\n",
    "# --- Step 3: Run prediction (via registry) ---\n",
    "if USE_REGISTRY and retrieved_model_version is not None and inference_data_snowpark is not None:\n",
    "    print(\"\\nRunning inference via Snowpark Python API...\")\n",
    "    predictions_df = retrieved_model_version.run(inference_data_snowpark)\n",
    "    # Show the first few predictions\n",
    "    predictions_df.show()\n",
    "else:\n",
    "    print(\"Registry-based inference was not executed. If you want to test registry inference, set USE_REGISTRY=1 and ensure the model is logged.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "narin.dhatwalia@snowflake.com",
   "authorId": "6650545469801",
   "authorName": "NDHATWALIA",
   "lastEditTime": 1750267336818,
   "notebookId": "6j2wygci252xtdcmo2gn",
   "sessionId": "7dead355-6102-4217-b003-02971bfcbdef"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
